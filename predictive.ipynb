{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Display uploaded file names\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Uploaded file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"graded_exams.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the first few rows to ensure it's loaded correctly\n",
    "from IPython.display import display\n",
    "\n",
    "# Display the first few rows as a formatted table\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define X (student characteristics) and Y (grade categories)\n",
    "X_columns = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n",
    "Y_columns = ['math grade', 'reading grade', 'writing grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode X (characteristics) and Y (grade categories)\n",
    "X_encoded = pd.get_dummies(df[X_columns])\n",
    "Y_encoded = pd.get_dummies(df[Y_columns])\n",
    "\n",
    "# Combine X and Y into a single DataFrame for Apriori\n",
    "df_encoded = pd.concat([X_encoded, Y_encoded], axis=1)\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Generate association rules (X â†’ Y relationships only)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter rules so that antecedents contain ONLY X values and consequents contain ONLY Y values\n",
    "X_labels = set(X_encoded.columns)\n",
    "Y_labels = set(Y_encoded.columns)\n",
    "\n",
    "rules_filtered = rules[\n",
    "    rules['antecedents'].apply(lambda antecedent: all(item in X_labels for item in antecedent)) &\n",
    "    rules['consequents'].apply(lambda consequent: all(item in Y_labels for item in consequent))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sort by highest lift value (strongest relationships)\n",
    "rules_sorted = rules_filtered.sort_values(by=\"lift\", ascending=False)\n",
    "\n",
    "# Display the strongest association rules\n",
    "from IPython.display import display\n",
    "display(rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter association rules where the consequent is a failure in any subject\n",
    "failure_rules = rules_sorted[rules_sorted['consequents'].astype(str).str.contains(\"Failure\")]\n",
    "\n",
    "# Group by failure category and sum lift values (higher lift means stronger relationship)\n",
    "failure_lift_sums = failure_rules.groupby(failure_rules['consequents'].astype(str))['lift'].sum()\n",
    "\n",
    "# Convert to percentages\n",
    "failure_percentages = (failure_lift_sums / failure_lift_sums.sum()) * 100\n",
    "\n",
    "# Define colors\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(failure_percentages, labels=failure_percentages.index, autopct='%1.1f%%', colors=colors, startangle=140, wedgeprops={'edgecolor': 'white'})\n",
    "\n",
    "# Title\n",
    "plt.title(\"Failure Distribution Based on Characteristics with Strongest Relationships\")\n",
    "\n",
    "# Show chart\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
